---
title: "arg2"
---
```{r setup, include=FALSE}
library(tidyverse)
library(memoise)
```

```{r general functions}
normalize <- function(x) {
  if (sum(x)==0) x else x/sum(x)
}
```

```{r functions}
agent_choose <- function(actions) {
  # given the agent's trait-determined weights on each legal action, make a
  # random decision among those that are available:
  stopifnot(any(actions > 0))
  probabilities <- normalize(unlist(actions))
  sample(names(actions), 1, prob = probabilities) %>% as.character
}



agent_update_actions <- function(actions, state, parameters) {
  # take the 'actions' tbl that initially holds a 1 for all legal actions and 0
  # for impossible actions, and apply our knowledge of the actor's traits of
  # (E)fficiency, (R)isk_awareness and (P)lacement_rule_comprehension to give
  # new, characteristic weights to all legal actions:
  actions_excel <- lookup_state_in_excel_file_memoized(state)
  actions_excel <- actions_excel %>% as.list
  prob_ok <- (parameters$ok / sum(actions_excel == 'ok'))
  prob_error <- ((1-parameters$ok) / sum(!actions_excel %in% c('ok', 'x')))
  actions[actions_excel == 'ok'] <- actions[actions_excel == 'ok'] * prob_ok
  actions[actions_excel == 'E'] <- actions[actions_excel == 'E'] * prob_error
  actions[actions_excel == 'r'] <- actions[actions_excel == 'r'] * prob_error
  actions[actions_excel == 'RR'] <- actions[actions_excel == 'RR'] * prob_error
  actions[actions_excel == '1/2r'] <- actions[actions_excel == '1/2r'] * prob_error
  actions[actions_excel == 'P'] <- actions[actions_excel == 'P'] * prob_error
  # if(!sum(actions) > .99) browser()
  if(!sum(actions) < 1.01) browser()
  # actions[actions_excel == 'E'] <- actions[actions_excel == 'E'] * PARAMETERS$E
  # actions[actions_excel == 'r'] <- actions[actions_excel == 'r'] * PARAMETERS$r
  # actions[actions_excel == 'RR'] <- actions[actions_excel == 'RR'] * PARAMETERS$RR
  # actions[actions_excel == '1/2r'] <- actions[actions_excel == '1/2r'] * (PARAMETERS$r/2)
  # actions[actions_excel == 'P'] <- actions[actions_excel == 'P'] * PARAMETERS$P
  actions
}



lookup_state_in_excel_file <- function(state) {
  ## compress state into single string representation
  state_chr <- state %>% state_wider %>% unlist %>% as.character %>% paste0(collapse = ' ')
  ## load excel table with states and actions
  xlsx <- readxl::read_excel('states and actions.xlsx', skip = 2)
  all_states_chr <- xlsx %>% select(rare:featB) %>% 
    apply(1, paste0, collapse = ' ')
  if (sum(state_chr == all_states_chr) != 1) browser()
  stopifnot(sum(state_chr == all_states_chr) == 1)
  ## identify actions that correspond to state
  actions <- xlsx[state_chr == all_states_chr,] %>% select(new:assB)
  stopifnot(nrow(actions) == 1)
  stopifnot(isTRUE(all.equal(colnames(actions), c("new", "qA", "qB", "assA", "assB"))))
  actions
}



lookup_state_in_excel_file_memoized <- memoise::memoize(lookup_state_in_excel_file)
state_wider <- function(state) {
  state %>% pivot_wider(names_from = feature, values_from = c(slot, card))
}



simulation <- function(population, parameters) {
  
  disable_invalid_actions <- function() {
    # run as first step given each new state, set to 0 all those actions that are
    # impossible ("not legal") given the current state (e.g., 'new card' when both
    # features of the current card are still unknown)
    actions <- tribble(
    ## initialize action space
      ~new, ~qA, ~qB, ~assA, ~assB,
      1, 1, 1, 1, 1
    )
    if (enforce_new_as_next_action) {
      return(tribble(
        ~new, ~qA, ~qB, ~assA, ~assB,
        1, 0, 0, 0, 0
      ))
    }
    if (isTRUE(all_equal(state$card, c('x', 'x')))) {
      actions$new <- 0
    }
    if ((state %>% filter(feature == 'A') %>% .$card) != 'x') {
      actions$qA <- 0
    }
    if ((state %>% filter(feature == 'B') %>% .$card) != 'x') {
      actions$qB <- 0
    }
    temp <- state %>% filter(feature == 'A') %>% select(slot, card)
    if (temp$slot == 'full' || temp$card == 'x') {
      actions$assA <- 0
    }
    temp <- state %>% filter(feature == 'B') %>% select(slot, card)
    if (temp$slot == 'full' || temp$card == 'x') {
      actions$assB <- 0
    }
    return(actions)
  }
  
  
  
  game_update_state <- function(chosen_action) {
    # given the current state and the agent's selection of one action, execute
    # action and update the global variable representing the game state
    
    ## this function works with side effects / global assignments / <<-
    if (chosen_action == 'new') {
      ## sample next card
      card <<- population %>% filter(card == card_sequence[card_sequence_index])
      card_sequence_index <<- card_sequence_index + 1
      ## reset state
      state[state$feature == 'A',]$card <<- 'x'
      state[state$feature == 'B',]$card <<- 'x'
    } else if (chosen_action == 'qA') {
      state[state$feature == 'A',]$card <<- card[card$feature == 'A',]$value
    } else if (chosen_action == 'qB') {
      state[state$feature == 'B',]$card <<- card[card$feature == 'B',]$value
    } else if (chosen_action == 'assA') {
      browser()
      state[state$feature == 'A',]$slot <<- 'full'
    } else if (chosen_action == 'assB') {
      state[state$feature == 'B',]$slot <<- 'full'
    }
  }
  
  
  
  update_history <- function() {
    history_row <- bind_cols(
      i = i, 
      state %>% state_wider, 
      actions,
      chosen_action = chosen_action, 
      card %>% pivot_wider(names_from = feature, values_from = value))
    history <<- bind_rows(history, history_row)
  }
  
  
  
  state <- tribble(
    ~rare, ~feature, ~slot, ~card,
    RARE_FEATURE, 'A', '[   ]', 'x',
    RARE_FEATURE, 'B', '[   ]', 'x'
  )
  
  card_sequence <- sample(1:max(population$card))
  card_sequence_index <- 1
  
  ## initialize game
  history <- list()
  enforce_new_as_next_action <- TRUE
  record_slotA <- ''
  record_slotB <- ''
  
  ## play game
  for (i in 1:100) {
    actions <- disable_invalid_actions()
    actions <- agent_update_actions(actions, state, parameters)
    if (!(any(actions > 0))) browser()
    chosen_action <- agent_choose(actions)
    if (chosen_action == 'new') {
      if (card_sequence_index > length(card_sequence)) {
        break  ## game over
      }
    }
    game_update_state(chosen_action)
    
    if (chosen_action == 'assA') {
      record_slotA <- state$card[state$feature == 'A']
    }
    if (chosen_action == 'assB') {
      record_slotB <- state$card[state$feature == 'B']
    }
    
    update_history()
    
    enforce_new_as_next_action <- chosen_action %in% c('assA', 'assB')
    
    if (isTRUE(all_equal(state$slot, c('full', 'full')))) {
      break  ## game over
    }
  }
  
  ## result: the whole log
  history
}
```

Run the simulation: set one or more dimensions on which we vary parameters, feed them to the simulation, get a resulting data structure for later analysis.

```{r run}
## set parameter ranges and other initial values:
set.seed(123)
RUNS <- 3
RARE_FEATURE <- 'A'

## actor's parameters on (E)fficiency, (R)isk and comprehension of (P)lacement
## rules:
PARAMETERS <- list()
PARAMETERS$ok <- .1
# PARAMETERS$E <- .1
# PARAMETERS$r <- .1
# PARAMETERS$RR <- .1
PARAMETERS$P <- .1

## what we vary to simulate a range of setups:
RANGE_OK <- seq(.1, .99999, length.out = 9)

## build list of parameter variations to feed into the simulation:
sim_params <- expand.grid(
  run = 1:RUNS,
  ok = RANGE_OK
) %>% as.list

## the card stack with which we start the simulation:
POPULATION <- tribble(~card, ~A, ~B,
                      1, 'long', 'long',
                      2, 'long', 'long',
                      3, 'long', 'short',
                      4, 'short', 'long',
                      5, 'short', 'long',
                      6, 'short', 'long',
                      7, 'short', 'long',
                      8, 'short', 'long',
                      9, 'short', 'long',
                      10, 'short', 'short',
                      11, 'short', 'short',
                      12, 'short', 'short',
                      13, 'short', 'short',
                      14, 'short', 'short',
                      15, 'short', 'short'
  ) %>% pivot_longer(A:B, names_to = 'feature', values_to = 'value')

## raw output is a list of histories, length determined by RANGE_OK:
out_raw <- pmap(sim_params,
                function(run, ok) {
                  PARAMETERS$ok <- ok
                  simulation(population = POPULATION,
                             parameters = PARAMETERS) %>%
                    mutate(param_ok = ok,
                           run = run)
                }) %>% 
  bind_rows

```

Analyses:

```{r}
# How often did both slots end up filled?
outcome_both_slots_full <- out_raw %>% 
  group_by( param_ok, run ) %>% 
  filter( i == max(i) ) %>%
  mutate( both_slots_full = slot_A != "[   ]" & slot_B != "[   ]" ) %>% 
  ungroup %>% 
  group_by( param_ok ) %>% 
  summarize( both_slots_full = sum( both_slots_full ))
outcome_both_slots_full
# place for plotting here
```

```{r}
# How often did both slots get filled with a long feature?
```



```{r run}
# out %>% ggplot(aes(ok, steps)) +
#   stat_summary(geom = 'line', fun.data = mean_se) +
# stat_summary(geom = 'pointrange', fun.data = mean_se)
```

```{r}
# out %>% mutate(solved = steps < 11) %>% group_by(ok) %>% summarize(mean(solved))
```

```{r}
# out %>% group_by(ok) %>% summarize(perc_solved = mean(steps)) %>% ggplot(aes(ok, perc_solved)) + geom_point() + geom_line() + ylim(0, 1)
```

